{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recherche et alignement : outil de recherche iconographique dans la base de données Gallica, Joconde et Europeana\n",
        "\n",
        "Cet outil permet la récupération de données (textuelles et iconographiques) à partir de termes de recherche de la bases de données : Gallica, Joconde et Europeana\n",
        "\n",
        "*Document d'entrée* : mot-clé.\n",
        "\n",
        "*Documents de sortie* : Dans le dossier de travail, les fichiers de données ainsi que les fichiers téléchargés"
      ],
      "metadata": {
        "id": "DeNYERyGkyIF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2vKBGDIvjkP",
        "cellView": "form",
        "collapsed": true
      },
      "source": [
        "# Connexion du notebook à son compte Google Drive et signalement du dossier de travail :\n",
        "\n",
        "\"\"\"\n",
        "Google Colab notebook.\n",
        "Python == 3.7.11\n",
        "\n",
        "Marina Giardinetti\n",
        "2024\n",
        "\"\"\"\n",
        "\n",
        "## Installation des bibliothèques et connexion au compte Google Drive\n",
        "\n",
        "# Désinstallation et installation spécifique de pyOpenSSL\n",
        "!pip uninstall pyOpenSSL==0.15.1 -y\n",
        "!pip install pyOpenSSL==17.2.0\n",
        "\n",
        "# Installation des bibliothèques nécessaires\n",
        "!pip install utils soup2dict langdetect xmltojson unidecode==1.2.0 folium\n",
        "\n",
        "# Importation des bibliothèques\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Connexion à Google Drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Indiquer le chemin vers le dossier de travail sur le Google Drive\n",
        "work_dir = '/content/drive/My Drive/API/' # @param {type:\"string\"}\n",
        "\n",
        "# Création du dossier de travail s'il n'existe pas encore\n",
        "if not os.path.exists(work_dir):\n",
        "    os.makedirs(work_dir)\n",
        "os.chdir(work_dir)\n",
        "\n",
        "# Configuration des en-têtes et définition du terme à chercher\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36'}\n",
        "search_term = \"cleopatre\" # @param {type:\"string\"}\n",
        "\n",
        "# Création et changement de répertoire pour le terme à chercher\n",
        "os.makedirs(search_term, exist_ok=True)\n",
        "os.chdir(search_term)\n",
        "\n",
        "# Chemin du dossier\n",
        "dir_path = os.path.join(work_dir, search_term)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gallica"
      ],
      "metadata": {
        "id": "TYeSQNvKVTcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import requests\n",
        "from collections import OrderedDict\n",
        "from bs4 import BeautifulSoup\n",
        "import xmltodict\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration du chemin de travail\n",
        "os.chdir(dir_path)\n",
        "dossier_gallica = 'images_gallica'\n",
        "os.makedirs(dossier_gallica, exist_ok=True)\n",
        "donnees_gallica = {}\n",
        "\n",
        "# Création du lien de recherche Gallica\n",
        "if ' ' in search_term:\n",
        "    nom_lien = search_term.replace(' ', '%20')\n",
        "else:\n",
        "    nom_lien = search_term\n",
        "url_gallica = f\"https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=dc.title%20adj%20{nom_lien}&maximumRecords=49&deway=%20any%207\"\n",
        "\n",
        "# Requête à Gallica\n",
        "reponse = requests.get(url_gallica, verify=False, headers=headers, timeout=5)\n",
        "\n",
        "# Parsing de la réponse XML\n",
        "parse = BeautifulSoup(reponse.content, 'html.parser')\n",
        "with open('temp.xml', 'w') as fichier_temporaire:\n",
        "    fichier_temporaire.write(parse.prettify())\n",
        "with open('temp.xml', 'r') as fichier_temporaire:\n",
        "    gallica_dict = xmltodict.parse(fichier_temporaire.read())\n",
        "os.remove('temp.xml')\n",
        "\n",
        "# Extraction des données\n",
        "for record in gallica_dict['srw:searchretrieveresponse']['srw:records']['srw:record']:\n",
        "    titre = ''\n",
        "    date = ''\n",
        "    auteur = ''\n",
        "    types = ''\n",
        "    sujet = ''\n",
        "    lien_image = ''\n",
        "    for cle, valeur in record.items():\n",
        "        if cle == 'srw:recorddata':\n",
        "            for cle2, valeur2 in valeur.items():\n",
        "                for cle3, valeur3 in valeur2.items():\n",
        "                    if cle3 == 'dc:title':\n",
        "                        titre = re.sub(r\"[][]\", '', str(valeur3))\n",
        "                        donnees_gallica[titre] = {}\n",
        "                    if cle3 == 'dc:date':\n",
        "                        date = valeur3\n",
        "                    if cle3 == 'dc:creator':\n",
        "                        auteur = valeur3\n",
        "                    if cle3 == 'dc:type':\n",
        "                        types = valeur3\n",
        "                    if cle3 == 'dc:subject':\n",
        "                        sujet = valeur3\n",
        "                    if cle3 == 'dc:identifier':\n",
        "                        identifiants = valeur3 if isinstance(valeur3, list) else [valeur3]\n",
        "                        for identifiant in identifiants:\n",
        "                            id_match = re.findall('b[a-z0-9]{4,}', str(identifiant))\n",
        "                            for identifiant_trouve in id_match:\n",
        "                                lien_image = f'http://gallica.bnf.fr/iiif/ark:/12148/{identifiant_trouve}/f1/full/3000/0/native.jpg'\n",
        "                                chemin_image = os.path.join(chemin_dossier, dossier_gallica, f'{identifiant_trouve}.jpg')\n",
        "                                time.sleep(15)\n",
        "                                requete_image = requests.get(lien_image, headers=headers, stream=True)\n",
        "                                with open(chemin_image, 'wb') as f:\n",
        "                                    f.write(requete_image.content)\n",
        "    donnees_gallica[titre] = {'Date': date, 'Auteur': auteur, 'Type': types, 'Sujet': sujet, 'Lien': lien_image}\n",
        "\n",
        "# Conversion en DataFrame et exportation en Excel\n",
        "df_gallica = pd.DataFrame.from_dict(donnees_gallica, orient='index')\n",
        "df_gallica.to_excel('donnees_gallica.xlsx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dnYUOOohfIZl",
        "outputId": "9df92bcd-d67a-4702-d522-123d8de4dd6a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1100: InsecureRequestWarning: Unverified HTTPS request is being made to host 'gallica.bnf.fr'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/lib/python3.10/html/parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
            "  k = self.parse_starttag(i)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Europeana"
      ],
      "metadata": {
        "id": "6Pp3Ij1kpPqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import pandas as pd\n",
        "from langdetect import detect, LangDetectException\n",
        "import ssl\n",
        "from urllib.error import HTTPError\n",
        "import urllib\n",
        "\n",
        "# Configuration du chemin de travail\n",
        "os.chdir(dir_path)\n",
        "europeana_images_dir = 'europeana_images'\n",
        "os.makedirs(europeana_images_dir, exist_ok=True)\n",
        "europeana_data = {}\n",
        "\n",
        "# Création du lien de recherche Europeana\n",
        "search_term_encoded = search_term.replace(' ', '%20') if ' ' in search_term else search_term\n",
        "europeana_search_url = f\"https://api.europeana.eu/record/v2/search.json?query={search_term_encoded}&rows=100&theme=art&wskey=alemalle\"\n",
        "search_request = urllib.request.Request(europeana_search_url)\n",
        "\n",
        "try:\n",
        "    search_response = urllib.request.urlopen(search_request)\n",
        "    parsed_response = BeautifulSoup(search_response, 'html.parser')\n",
        "    search_results = json.loads(parsed_response.text)\n",
        "except HTTPError:\n",
        "    print('Pas de téléchargement possible pour la base Europeana avec cette recherche')\n",
        "    search_results = {}\n",
        "\n",
        "# Désactiver les vérifications SSL\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "# Extraction des données\n",
        "if 'items' in search_results:\n",
        "    for item in search_results['items']:\n",
        "        title = ''\n",
        "        authors = ''\n",
        "        item_type = ''\n",
        "        subjects = ''\n",
        "        image_link = ''\n",
        "\n",
        "        if 'title' in item:\n",
        "            title = item['title'][0] if isinstance(item['title'], list) else item['title']\n",
        "            cleaned_title = re.sub(r\"[\\['\\]]\", '', title)\n",
        "\n",
        "        if 'dcCreator' in item:\n",
        "            authors = str(item['dcCreator'])\n",
        "\n",
        "        if 'edmConceptPrefLabelLangAware' in item and 'fr' in item['edmConceptPrefLabelLangAware']:\n",
        "            item_type = str(item['edmConceptPrefLabelLangAware']['fr'])\n",
        "\n",
        "        if 'edmConceptLabel' in item:\n",
        "            for concept in item['edmConceptLabel']:\n",
        "                for value in concept.values():\n",
        "                    try:\n",
        "                        if detect(value) == 'fr':\n",
        "                            subjects = str(value)\n",
        "                    except LangDetectException:\n",
        "                        pass\n",
        "\n",
        "        if 'edmIsShownBy' in item:\n",
        "            for link in item['edmIsShownBy']:\n",
        "                image_filename = os.path.join(work_dir, search_term, europeana_images_dir, re.sub('\\/', '_', cleaned_title) + '.jpg')\n",
        "                if 'gallica' not in link:\n",
        "                    try:\n",
        "                        response = requests.get(link, headers=headers, stream=True)\n",
        "                        with open(image_filename, 'wb') as image_file:\n",
        "                            image_file.write(response.content)\n",
        "                    except (NameError, requests.exceptions.SSLError, OSError):\n",
        "                        pass\n",
        "\n",
        "        europeana_data[cleaned_title] = {'Auteur': authors, 'Type': item_type, 'Sujet': subjects, 'Lien': link}\n",
        "\n",
        "# Conversion des données en DataFrame et exportation en fichier Excel\n",
        "europeana_df = pd.DataFrame.from_dict(europeana_data, orient='index')\n",
        "europeana_df.to_excel('europeana_data.xlsx')\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "F-dprLTbfLzF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Joconde\n",
        "Téléchargement des métadonnées"
      ],
      "metadata": {
        "id": "p0lOoyLCryb3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGvqf6C5K33D"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration du chemin de travail\n",
        "os.chdir(dir_path)\n",
        "joconde_data = {}\n",
        "\n",
        "# Création du lien de recherche Joconde\n",
        "search_term_encoded = search_term.replace(' ', '%20')\n",
        "joconde_search_url = f\"https://data.culture.gouv.fr/api/records/1.0/search/?dataset=base-joconde-extrait&q={search_term_encoded}&rows=10000\"\n",
        "\n",
        "# Requête à Joconde\n",
        "response = urllib.request.urlopen(joconde_search_url)\n",
        "soup = BeautifulSoup(response, 'html.parser')\n",
        "joconde_records = json.loads(soup.text)\n",
        "\n",
        "# Extraction des données\n",
        "for record in joconde_records.get('records', []):\n",
        "    fields = record.get('fields', {})\n",
        "    title = fields.get('titre', '')\n",
        "    author = fields.get('auteur', '')\n",
        "    materials = fields.get('materiaux_techniques', '')\n",
        "    subject = fields.get('sujet_represente', '')\n",
        "    date = fields.get('epoque', fields.get('periode_de_creation', ''))\n",
        "\n",
        "    joconde_data[title] = {\n",
        "        'Date': date,\n",
        "        'Auteur': author,\n",
        "        'Matériaux': materials,\n",
        "        'Sujet': subject\n",
        "    }\n",
        "\n",
        "# Conversion des données en DataFrame et exportation en fichier Excel\n",
        "joconde_df = pd.DataFrame.from_dict(joconde_data, orient='index')\n",
        "joconde_df.to_excel('donnees_joconde.xlsx')\n"
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}